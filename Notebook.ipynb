{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a74675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 12:41:28.470618: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 12:41:30.028121: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 12:41:30.028244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-08 12:41:30.028258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.argv = [''] #fix parser issue\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import trange\n",
    "\n",
    "from networks import CNN\n",
    "from parser import args\n",
    "from summary import Summary\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a6ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval_during_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23cb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(network, criterion, test_loader, summary = None):\n",
    "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='Accuracy')\n",
    "    labels = []\n",
    "    test_iter = iter(test_loader)\n",
    "#     for eval_steps in trange(len(test_loader), leave=False, file=sys.stdout,\n",
    "#                             desc='   Evaluation Progress', unit_scale=False):\n",
    "    for eval_steps in range(len(test_loader)):\n",
    "        input, target = next(test_iter)\n",
    "\n",
    "        if(len(input.shape) <= 3):\n",
    "            input = tf.expand_dims(input, -1)\n",
    "\n",
    "        pred = network(input)\n",
    "        labels += [tf.argmax(pred, axis=1)]\n",
    "        loss = criterion(target, pred)\n",
    "        accuracy(target, pred)\n",
    "        if(summary is not None):\n",
    "            summary.step(loss, target, pred, eval=True)\n",
    "    return accuracy.result() * 100, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07850c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(network, criterion, data, summary, optimizer):\n",
    "    input, target = data\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = network(input)\n",
    "        loss = criterion(target, pred)\n",
    "\n",
    "    gradients = tape.gradient(loss, network.trainable_variables,\n",
    "                                    unconnected_gradients=tf.UnconnectedGradients.ZERO)\n",
    "    optimizer.apply_gradients(zip(gradients, network.trainable_variables))\n",
    "\n",
    "    summary.step(loss, target, pred, eval=False)\n",
    "\n",
    "    del tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa29acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, optimizer, criterion, checkpoint, checkpoint_manager,\n",
    "            train_loader, test_loader, summary):\n",
    "\n",
    "    training_steps = len(train_loader)\n",
    "    steps_done = checkpoint.step.numpy() + 1\n",
    "    train_iter = iter(train_loader)\n",
    "    x, y = tf.random.uniform([args.batch_size,28,28,1]), tf.random.uniform([args.batch_size,1])\n",
    "    t_step = tf.function(training_step).get_concrete_function(network, criterion, (x,y),summary, optimizer)\n",
    "        \n",
    "    for steps in trange(int(steps_done), training_steps, desc='Training Progress', file=sys.stdout):\n",
    "        # fetch data\n",
    "        input, target = next(train_iter)\n",
    "\n",
    "        # expand input shape in case of only 1 channel\n",
    "        if(len(input.shape) <= 3):\n",
    "            input = tf.expand_dims(input, -1)\n",
    "        t_step(network, criterion,(input, target),summary)\n",
    "\n",
    "        # evaluation step\n",
    "        if(args.eval_during_training and steps > 0\n",
    "                    and steps % args.num_eval_steps == 0):\n",
    "            eval_model(network, criterion, test_loader, summary)\n",
    "            summary.write(steps, eval=True)\n",
    "\n",
    "        #  log training accuracy and update checkpoint\n",
    "        if(steps % args.num_summary_steps == 0):\n",
    "            summary.write(steps, eval=False)\n",
    "            if(summary.max_test_accuracy <= checkpoint.best_test):\n",
    "                checkpoint.best_train.assign(summary.max_train_accuracy)\n",
    "                checkpoint.best_test.assign(summary.max_test_accuracy)\n",
    "                checkpoint.step.assign(steps)\n",
    "                checkpoint_manager.save(checkpoint_number=steps//args.num_summary_steps)\n",
    "\n",
    "    # evaluate model after finishing training epochs\n",
    "    accuracy, predictions = eval_model(network, criterion, test_loader,summary)\n",
    "\n",
    "    if(summary.max_test_accuracy <= checkpoint.best_test):\n",
    "        checkpoint.best_train.assign(summary.max_train_accuracy)\n",
    "        checkpoint.best_test.assign(summary.max_test_accuracy)\n",
    "        checkpoint.step.assign(steps)\n",
    "        checkpoint_manager.save(checkpoint_number=steps//args.num_summary_steps)\n",
    "\n",
    "    summary.write(training_steps + 1, eval=True)\n",
    "    summary.write(training_steps + 1, eval=False)\n",
    "\n",
    "    print('Training accuracy: ', summary.max_train_accuracy)\n",
    "    print('Evaluation accuracy: ', summary.max_test_accuracy)\n",
    "    summary.writer.close()\n",
    "    return accuracy, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49326979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs found:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 12:41:31.443663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:31.513614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:31.514609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Make sure computing on cuda\n",
    "print('GPUs found: ', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24fe2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(args.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602a7a3",
   "metadata": {},
   "source": [
    "# Training a 'client' model on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acaf9bc",
   "metadata": {},
   "source": [
    "### Random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e61a90c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:01:29.761000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 11:01:29.761536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:01:29.762094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:01:29.762504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:01:30.727429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:01:30.727728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:01:30.728034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:01:30.728509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-02-08 11:01:31.107224: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2023-02-08 11:01:31.214851: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Training Progress:   0%|                             | 0/131249 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:01:32.517391: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2023-02-08 11:01:32.937848: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-08 11:01:33.888687: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f04a38847b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-08 11:01:33.888717: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-02-08 11:01:33.927751: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-08 11:01:34.205173: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-08 11:01:34.258125: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|███████████████| 131249/131249 [06:20<00:00, 345.17it/s]\n",
      "Training accuracy:  tf.Tensor(100.0, shape=(), dtype=float32)\n",
      "Evaluation accuracy:  tf.Tensor(98.96, shape=(), dtype=float32)\n",
      "Random Initialization MNIST model:\n",
      "98.909996\n",
      "[0.99693878 0.99647577 0.98643411 0.98811881 0.98879837 0.98766816\n",
      " 0.9874739  0.98735409 0.9825462  0.98810704 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anwar/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "experiment = 'c_mnist'\n",
    "args.dataset = 'mnist'\n",
    "\n",
    "exp_path = os.path.join(args.model_dir, experiment)\n",
    "utils.initialize_dirs(exp_path)\n",
    "\n",
    "summary = Summary(experiment)\n",
    "network = CNN()\n",
    "optimizer = utils.initialize_optimizer()\n",
    "criterion = utils.initialize_criterion()\n",
    "checkpoint, checkpoint_manager = utils.initialize_checkpoint(network, optimizer, exp_path)\n",
    "\n",
    "# data loading\n",
    "train_loader, test_loader, targets = utils.initialize_dataloaders()\n",
    "\n",
    "#train client network\n",
    "accuracy, predictions = train(network, optimizer, criterion, checkpoint, checkpoint_manager, train_loader, test_loader, summary)\n",
    "p, r, f, s = precision_recall_fscore_support(targets, predictions.reshape(-1), average=None,labels=np.arange(20))\n",
    "    \n",
    "print('Random Initialization MNIST model:')\n",
    "print(accuracy.numpy())\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31bd1a",
   "metadata": {},
   "source": [
    "### Set seed for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef08f374",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:46:23.850052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 11:46:23.850959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:46:23.851380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:46:23.851678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:46:24.808634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:46:24.809337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:46:24.809607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 11:46:24.810305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Training Progress:   0%|                             | 0/131249 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 11:46:27.057959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2023-02-08 11:46:28.104811: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-08 11:46:29.687679: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f6fae05c5c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-08 11:46:29.687702: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-02-08 11:46:29.712645: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-08 11:46:29.971559: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-08 11:46:30.022520: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|███████████████| 131249/131249 [05:05<00:00, 428.93it/s]\n",
      "Training accuracy:  tf.Tensor(100.0, shape=(), dtype=float32)\n",
      "Evaluation accuracy:  tf.Tensor(98.94, shape=(), dtype=float32)\n",
      "Set Seed Initialization MNIST model:\n",
      "98.9\n",
      "[0.99489796 0.99471366 0.98546512 0.98811881 0.99592668 0.98542601\n",
      " 0.98643006 0.98929961 0.98562628 0.98315164 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/anwar/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "experiment = 'c_mnist_setseed'\n",
    "args.dataset = 'mnist'\n",
    "\n",
    "exp_path = os.path.join(args.model_dir, experiment)\n",
    "utils.initialize_dirs(exp_path)\n",
    "\n",
    "summary = Summary(experiment)\n",
    "network = CNN(42)\n",
    "optimizer = utils.initialize_optimizer()\n",
    "criterion = utils.initialize_criterion()\n",
    "checkpoint, checkpoint_manager = utils.initialize_checkpoint(network, optimizer, exp_path)\n",
    "\n",
    "# data loading\n",
    "train_loader, test_loader, targets = utils.initialize_dataloaders()\n",
    "\n",
    "#train client network\n",
    "accuracy, predictions =train(network, optimizer, criterion, checkpoint, checkpoint_manager, train_loader, test_loader, summary)\n",
    "p, r, f, s = precision_recall_fscore_support(targets, predictions.reshape(-1), average=None,labels=np.arange(20))\n",
    "    \n",
    "print('Set Seed Initialization MNIST model:')\n",
    "print(accuracy.numpy())\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716ba9a",
   "metadata": {},
   "source": [
    "# Training a 'client' model on Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59e49b",
   "metadata": {},
   "source": [
    "### Random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc27b501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 12:41:41.318441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 12:41:41.318854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:41.319241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:41.319526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:42.222300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:42.222618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:42.222883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-08 12:41:42.223409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2629 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|                             | 0/131249 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ConcreteFunction training_step(network, criterion, data, summary, optimizer) was constructed with UnknownArgument value <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7ff0c026e210> in network, but was called with CNN value <networks.s_model.CNN object at 0x7ff0cf8e0810>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             return self._call_with_flat_signature(args, kwargs,\n\u001b[0;32m-> 1488\u001b[0;31m                                                   cancellation_manager)\n\u001b[0m\u001b[1;32m   1489\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1511\u001b[0m       raise TypeError(\n\u001b[0;32m-> 1512\u001b[0;31m           \u001b[0;34mf\"{self._flat_signature_summary()} takes {self._num_positional_args} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m           f\"positional arguments, got {len(args)}.\")\n",
      "\u001b[0;31mTypeError\u001b[0m: training_step(data, data_1) takes 2 positional arguments, got 4.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38291/3238382016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#train client network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_38291/3667226060.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, optimizer, criterion, checkpoint, checkpoint_manager, train_loader, test_loader, summary)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# evaluation step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1472\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \"\"\"\n\u001b[0;32m-> 1474\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1488\u001b[0m                                                   cancellation_manager)\n\u001b[1;32m   1489\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_flat_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m           return self._call_with_structured_signature(args, kwargs,\n\u001b[0;32m-> 1484\u001b[0;31m                                                       cancellation_manager)\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_check_missing_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_check_unexpected_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_check_arg_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m     return self._call_flat(\n\u001b[1;32m   1565\u001b[0m         \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_structured_signature_check_arg_types\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m       self._structured_signature_check_arg_type(arg, spec, name,\n\u001b[0;32m-> 1606\u001b[0;31m                                                 signature_context)\n\u001b[0m\u001b[1;32m   1607\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m       self._structured_signature_check_arg_type(arg, kwarg_specs[name], name,\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_structured_signature_check_arg_type\u001b[0;34m(self, arg, spec, name, signature_context)\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marg_matches_spec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m           raise TypeError(\n\u001b[0;32m-> 1662\u001b[0;31m               \u001b[0;34mf\"ConcreteFunction {self._structured_signature_summary()} was \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m               \u001b[0;34mf\"constructed with {type(spec_piece).__name__} value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m               \u001b[0;34mf\"{spec_piece} in {name}, but was called with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ConcreteFunction training_step(network, criterion, data, summary, optimizer) was constructed with UnknownArgument value <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7ff0c026e210> in network, but was called with CNN value <networks.s_model.CNN object at 0x7ff0cf8e0810>."
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "experiment = 'c_fmnist'\n",
    "args.dataset = 'fmnist'\n",
    "\n",
    "exp_path = os.path.join(args.model_dir, experiment)\n",
    "utils.initialize_dirs(exp_path)\n",
    "\n",
    "# data loading\n",
    "train_loader, test_loader, targets = utils.initialize_dataloaders()\n",
    "\n",
    "summary = Summary(experiment)\n",
    "network = CNN()\n",
    "network.build([1,28,28,1])\n",
    "optimizer = utils.initialize_optimizer()\n",
    "criterion = utils.initialize_criterion()\n",
    "checkpoint, checkpoint_manager = utils.initialize_checkpoint(network, optimizer, exp_path)\n",
    "\n",
    "\n",
    "#train client network\n",
    "accuracy, predictions = train(network, optimizer, criterion, checkpoint, checkpoint_manager, train_loader, test_loader, summary)\n",
    "p, r, f, s = precision_recall_fscore_support(targets, predictions.reshape(-1), average=None,labels=np.arange(20))\n",
    "    \n",
    "print('Random Initialization Fashion MNIST model:')\n",
    "print(accuracy.numpy())\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02788bd",
   "metadata": {},
   "source": [
    "### Set seed for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'c_fmnist_setseed'\n",
    "args.dataset = 'fmnist'\n",
    "\n",
    "exp_path = os.path.join(args.model_dir, experiment)\n",
    "utils.initialize_dirs(exp_path)\n",
    "\n",
    "summary = Summary(experiment)\n",
    "network = CNN(42)\n",
    "optimizer = utils.initialize_optimizer()\n",
    "criterion = utils.initialize_criterion()\n",
    "checkpoint, checkpoint_manager = utils.initialize_checkpoint(network, optimizer, exp_path)\n",
    "\n",
    "# data loading\n",
    "train_loader, test_loader, targets = utils.initialize_dataloaders()\n",
    "\n",
    "#train client network\n",
    "accuracy, predictions = train(network, optimizer, criterion, checkpoint, checkpoint_manager, train_loader, test_loader, summary)\n",
    "p, r, f, s = precision_recall_fscore_support(targets, predictions.reshape(-1), average=None,labels=np.arange(20))\n",
    "    \n",
    "print('Set Seed Initialization MNIST model:')\n",
    "print(accuracy.numpy())\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f67420",
   "metadata": {},
   "source": [
    "## Create dataset containing both MNIST and FMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(m_x_train, m_y_train), (m_x_test, m_y_test) = mnist.load_data()\n",
    "m_x_train = tf.cast(m_x_train, dtype=tf.float32)\n",
    "m_x_test = tf.cast(m_x_test, dtype=tf.float32)\n",
    "m_x_train, m_x_test = m_x_train / 255.0, m_x_test / 255.0\n",
    "\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train_old), (x_test, y_test_old) = fmnist.load_data()\n",
    "y_train = y_train_old + 10\n",
    "y_test = y_test_old + 10\n",
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "x_test = tf.cast(x_test, dtype=tf.float32)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "f_x_train = tf.concat([x_train, m_x_train],0)\n",
    "f_x_test = tf.concat([x_test, m_x_test],0)\n",
    "f_y_train = tf.concat([y_train, m_y_train],0)\n",
    "f_y_test = tf.concat([y_test, m_y_test],0)\n",
    "\n",
    "full_train_loader = tf.data.Dataset.from_tensor_slices((f_x_train, f_y_train)).shuffle(x_train.shape[0]).repeat(args.epochs).batch(args.batch_size)\n",
    "full_test_loader = tf.data.Dataset.from_tensor_slices((f_x_test, f_y_test)).batch(args.eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832baa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = ['c_mnist', 'c_fmnist']\n",
    "clients_setseed = ['c_mnist_setseed', 'c_fmnist_setseed']\n",
    "\n",
    "n_clients = len(clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86fb3f",
   "metadata": {},
   "source": [
    "# Creating Federated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c03394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20), dtype=float32, numpy=\n",
       "array([[-0.10439795,  0.12120815, -0.01573612,  0.04494804,  0.05239639,\n",
       "         0.13556068, -0.00365166, -0.07352076, -0.06002626,  0.16004483,\n",
       "         0.01198496, -0.00214229, -0.01947405,  0.07039872,  0.01709209,\n",
       "        -0.05730027,  0.07044452, -0.2693583 , -0.03279328,  0.07567452]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federal_model = CNN()\n",
    "federal_model(tf.random.uniform([1,28,28,1])) #initialize network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34baf5a1",
   "metadata": {},
   "source": [
    "## Collecting client models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91aa05f",
   "metadata": {},
   "source": [
    "### Randomly initialized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0e267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 10:40:54.509994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2023-02-08 10:40:55.393898: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from trained_models/c_fmnist/ckpt-4...\n"
     ]
    }
   ],
   "source": [
    "cmodels=[]\n",
    "x = tf.random.uniform([1,28,28,1])\n",
    "for c in clients:\n",
    "        c_path = os.path.join(args.model_dir, c)\n",
    "        c_network = CNN()\n",
    "        c_optimizer = utils.initialize_optimizer()\n",
    "        c_checkpoint, c_checkpoint_manager = utils.initialize_checkpoint(c_network, c_optimizer, c_path)\n",
    "        c_network(x) # restore deferred variables\n",
    "        cmodels += [c_network]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a9316",
   "metadata": {},
   "source": [
    "### Averaging models initialized with the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9803aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from trained_models/c_mnist_setseed/ckpt-656...\n",
      "Resuming training from trained_models/c_fmnist_setseed/ckpt-656...\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n"
     ]
    }
   ],
   "source": [
    "cmodels=[]\n",
    "x = tf.random.uniform([1,28,28,1])\n",
    "for c in clients_setseed:\n",
    "        c_path = os.path.join(args.model_dir, c)\n",
    "        c_network = CNN()\n",
    "        c_optimizer = utils.initialize_optimizer()\n",
    "        c_checkpoint, c_checkpoint_manager = utils.initialize_checkpoint(c_network, c_optimizer, c_path)\n",
    "        c_network(x) # restore deferred variables\n",
    "        cmodels += [c_network]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a67fc",
   "metadata": {},
   "source": [
    "## Aggregating the weights of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e1d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.zeros_like(federal_model.conv1.kernel)\n",
    "conv1_b = tf.zeros_like(federal_model.conv1.bias)\n",
    "\n",
    "conv2 = tf.zeros_like(federal_model.conv2.kernel)\n",
    "conv2_b = tf.zeros_like(federal_model.conv2.bias)\n",
    "\n",
    "fc1 = tf.zeros_like(federal_model.fc1.kernel)\n",
    "fc1_b = tf.zeros_like(federal_model.fc1.bias)\n",
    "                        \n",
    "out = tf.zeros_like(federal_model.out.kernel)\n",
    "out_b = tf.zeros_like(federal_model.out.bias)\n",
    "for i in range(len(cmodels)):\n",
    "    conv1 += cmodels[i].conv1.kernel / len(cmodels)\n",
    "    conv1_b += cmodels[i].conv1.bias / len(cmodels)\n",
    "    \n",
    "    conv2 += cmodels[i].conv2.kernel / len(cmodels)\n",
    "    conv2_b += cmodels[i].conv2.bias / len(cmodels)\n",
    "    \n",
    "    fc1 += cmodels[i].fc1.kernel / len(cmodels)\n",
    "    fc1_b += cmodels[i].fc1.bias / len(cmodels)\n",
    "    \n",
    "    out += cmodels[i].out.kernel / len(cmodels)\n",
    "    out_b += cmodels[i].out.bias / len(cmodels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b4813",
   "metadata": {},
   "source": [
    "## Federated model equals the average weight of the client models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb58a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "federal_model.conv1.kernel = conv1\n",
    "federal_model.conv1.bias = conv1_b\n",
    "\n",
    "federal_model.conv2.kernel = conv2\n",
    "federal_model.conv2.bias = conv2_b\n",
    "\n",
    "federal_model.fc1.kernel = fc1\n",
    "federal_model.fc1.bias = fc1_b\n",
    "\n",
    "federal_model.out.kernel = out\n",
    "federal_model.out.bias = out_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a473643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = utils.initialize_criterion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d2069",
   "metadata": {},
   "source": [
    "### Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be87efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.92\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.883\n",
      " 0.    0.    0.996 0.723 0.    0.982 0.    0.   ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate federated network\n",
    "accuracy, labels = eval_model(federal_model, criterion, full_test_loader)\n",
    "p, r, f, s = precision_recall_fscore_support(f_y_test, labels.reshape(-1), average=None,labels=np.arange(20))\n",
    "\n",
    "print(accuracy.numpy())\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6914a1",
   "metadata": {},
   "source": [
    "### Set seed Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eae3f39",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 10:31:19.600217: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 376320000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.695\n",
      "[0.36938776 0.04493392 0.21414729 0.44455446 0.39002037 0.14686099\n",
      " 0.05845511 0.12062257 0.8275154  0.02081269 0.056      0.841\n",
      " 0.945      0.012      0.08       0.855      0.09       0.565\n",
      " 0.939      0.152     ]\n"
     ]
    }
   ],
   "source": [
    "# evaluate federated network\n",
    "accuracy, labels = eval_model(federal_model, criterion, test_loader)\n",
    "p, r, f, s = precision_recall_fscore_support(f_y_test, labels.reshape(-1), average=None,labels=np.arange(20))\n",
    "\n",
    "print(accuracy.numpy())\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af3826",
   "metadata": {},
   "source": [
    "## Averaging only the last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b2770",
   "metadata": {},
   "source": [
    "### Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17ebafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client model 0 :\n",
      "accuracy 5.7999997\n",
      "[0.         0.         0.         0.         0.00712831 0.0044843\n",
      " 0.         0.03015564 0.         0.         0.         0.\n",
      " 0.013      0.105      0.016      0.007      0.912      0.065\n",
      " 0.         0.        ]\n",
      "Client model 1 :\n",
      "accuracy 17.785\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.974\n",
      " 0.    0.    0.946 0.645 0.    0.992 0.    0.   ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cmodels)):\n",
    "    federal_model.conv1.kernel = cmodels[i].conv1.kernel\n",
    "    federal_model.conv1.bias = cmodels[i].conv1.bias\n",
    "\n",
    "    federal_model.conv2.kernel = cmodels[i].conv2.kernel\n",
    "    federal_model.conv2.bias = cmodels[i].conv2.bias\n",
    "\n",
    "    federal_model.fc1.kernel = cmodels[i].fc1.kernel\n",
    "    federal_model.fc1.bias = cmodels[i].fc1.bias\n",
    "\n",
    "    federal_model.out.kernel = out\n",
    "    federal_model.out.bias = out_b\n",
    "\n",
    "    # evaluate federated network\n",
    "    accuracy, labels = eval_model(federal_model, criterion, full_test_loader)\n",
    "    p, r, f, s = precision_recall_fscore_support(f_y_test, labels.reshape(-1), average=None,labels=np.arange(20))\n",
    "    \n",
    "    print('Client model', i, ':')\n",
    "    print('accuracy', accuracy.numpy())\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb36d6e",
   "metadata": {},
   "source": [
    "### Set seed initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cmodels)):\n",
    "    federal_model.conv1.kernel = cmodels[i].conv1.kernel\n",
    "    federal_model.conv1.bias = cmodels[i].conv1.bias\n",
    "\n",
    "    federal_model.conv2.kernel = cmodels[i].conv2.kernel\n",
    "    federal_model.conv2.bias = cmodels[i].conv2.bias\n",
    "\n",
    "    federal_model.fc1.kernel = cmodels[i].fc1.kernel\n",
    "    federal_model.fc1.bias = cmodels[i].fc1.bias\n",
    "\n",
    "    federal_model.out.kernel = out\n",
    "    federal_model.out.bias = out_b\n",
    "\n",
    "    # evaluate federated network\n",
    "    accuracy, labels = eval_model(federal_model, criterion, test_loader)\n",
    "    p, r, f, s = precision_recall_fscore_support(f_y_test, labels.reshape(-1), average=None,labels=np.arange(20))\n",
    "    \n",
    "    print('Client model', i, ':')\n",
    "    print('accuracy', accuracy.numpy())\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60903874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
